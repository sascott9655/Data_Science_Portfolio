#used titanic from kaggle

titanic.data <- read.csv('C:/Users/samsc/Desktop/ADS-500B/Data_and_Code2/titanic/train.csv', header = TRUE, sep = ',') #looking at the titanic training data

View(titanic.data)

#sibsp column is the siblings/spouses aboard the titanic
#parch columns is the parents/children aboard the titanic

#check for missing values in data set. this is a good initial habit when working with data in general. 
#we will also find how many unique values there are using sapply() function

sapply(titanic.data, function(x) sum(is.na(x)))#all na values are in the age column

sapply(titanic.data, function(x) length(unique(x))) #891 unique passenger ids (makes sense), 2 survived values (1 or 0, makes sense), etc...

#another way to estimate missing values is the Amelia package. 
#Using the missmap() function to plot missing values

#install.packages("Amelia")
library(Amelia)

missmap(titanic.data, main="Missing values vs observed") #shows all missing values are in the age column about 2 percent of all data

#replacing missing values with the mean age value:

titanic.data$Age[is.na(titanic.data$Age)] <- mean(titanic.data$Age,na.rm=T)
#identifies all rows where age is na is true and with that information finds the
#mean of the ages in all the data removing the na values.

#simplifying data by removing some columns using subset. Passenger Id = 1 is removed
#as well as Cabin rooms
titanic.data <- subset(titanic.data,select=c(2,3,5,6,7,8,10,12))

View(titanic.data)
#uses numbers to refer to the columns we want to keep 

#read.csv or read.table by default will encode the categorical variables as 
#factors. A factor is how R deals with categorical variables

is.factor(titanic.data$Sex) #returned False
is.factor(titanic.data$Survived) #FALSE
is.factor(titanic.data$Pclass)
is.factor(titanic.data$Name)
is.factor(titanic.data$Ticket)
is.factor(titanic.data$Embarked)

#however the categorical variables in this dataset all returned false. So we
#need to fix this so our model can encode our categorical variables as categorical
#variables.
#used copilot for assistance on this step:
categorical_cols <- c("Sex", "Survived", "Pclass", "Embarked")
titanic.data[categorical_cols] <- lapply(titanic.data[categorical_cols], as.factor)

#lapply vs sapply:
#lapply always will return a list sapply simplifies the result as vector

str(titanic.data) #check to see if categorical columns are Factors

is.factor(titanic.data$Sex) #return TRUE now we good!

#separate data in train/test split
train <- titanic.data[1:669,] #75% of data here
test <- titanic.data[670:891,]#25% of data here

#build our model using family=binomial (two classes or labels) in glm func:

model <- glm(Survived ~., family=binomial(link='logit'), data=train) #dot means all like in SQL
summary(model)


# algorithm did not converge properly so I commented it out. This is because factors like Name and Ticket
# have no predictive value and cause convergence issues


#much better and easier to read

#Sex male had the lowest p-value making it statistically significant in relation to survival
#negative coefficient for it suggests that males were least likely to survive
#This is due to women and children being the priority of passengers to save in lifeboats
#as the titanic was sinking.

#let's see how good our model is at predicting values for test instances
#By setting type='response, R will output probabilities in the form of P(y=1|X).
#Our decision boundary will be 0.5. If P(y=1|X) > 0.5 then y=1, otherwise 
#y=0

fitted.results <- predict(model, newdata=subset(test,select=c(2,3,4,5,6,7,8)), type='response')
fitted.results <- ifelse(fitted.results > 0.5, 1.0, 0.0)
misClasificError <- mean(fitted.results != test$Survived)
print(paste('Accuracy', 1-misClasificError))

length(fitted.results)
length(test$Survived)

#82 percent is decent performance from the model

#Plotting receiver operating curve (ROC) and calculate the area under the curve (AUC)
#which are typical performances measurements for a binary classifier.

#install.packages("ROCR")
library(ROCR)
p <- predict(model, newdata=subset(test, select = c(2,3,4,5,6,7,8)), type = 'response')
pr <- prediction(p, test$Survived)
prf <- performance(pr, measure='tpr', x.measure = "fpr")
plot(prf)
auc <- performance(pr,measure='auc')

auc <- auc@y.values[[1]]
auc #87.14 percent

#The ROC curve is generated by plotting the true positive rate (TPR) against the 
#false positive rate (FPR) at various threshold settings and AUC is under the ROC curve.
#TPR shows how much was it true that 1 was 1 and FPR shows how true was 1 when it was actually 0.
#A high AUC percent shows good predicitive ability.


#Credit to Shah 2020 for code I walked through it as a learning process for myself and 
#discovered more to learn

